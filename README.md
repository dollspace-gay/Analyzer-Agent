# Sequential Dialogue Architecture for Constrained LLM Analysis

## Abstract

Smaller-scale Large Language Models (LLMs), such as 7B-parameter models, offer significant advantages in efficiency and accessibility but often suffer from output degradation in complex, analytical tasks. This "model drift" typically manifests as affective softening, loss of structural integrity, and the insertion of non-committal hedging language, rendering their outputs unsuitable for rigorous, "sane" analysis.

This paper describes a **Sequential Dialogue Architecture (SDA)**, a hybrid governance framework that constrains a non-deterministic LLM using a deterministic, multi-turn Python orchestrator. This architecture transforms a single, complex generation task into a series of discrete, stateful, and programmatically audited "dialogue turns." By injecting specific governance modules at each turn, programmatically auditing the output for drift, and using a retry-or-fallback enforcement loop, the SDA successfully forces smaller models to produce structurally sound, precise, and analytically dense reports that would otherwise be characteristic of much larger, more-disciplined models.

---

## 1. Introduction

The proliferation of accessible, high-performance, and locally-runnable LLMs (e.g., 7B-13B parameter models) has opened new avenues for agentic systems. However, these models' utility is often undermined by their inherent non-determinism and tendency toward "drift."

When tasked with generating a long-form, multi-part analytical report in a single pass, these models reliably fail. Their output loses its formal cadence, adopts a conversational or "helpful" tone, and becomes saturated with affective softeners (*"it seems," "perhaps," "it's important to note"*) that destroy analytical precision.

**The core problem** is that a single, complex prompt asking for a 7-section report overloads the model's capacity for maintaining context, cadence, and structural integrity. The model "forgets" the initial, strict instructions by the time it begins generating the final sections.

This paper details a **Sequential Dialogue Architecture (SDA)**, a novel approach implemented in the "Analyzer-Agent". The SDA posits that "sanity" and "precision" should not be expected from the model but **enforced by an external, deterministic supervisor**. This architecture externalizes the system's "discipline" from the model's weights into the surrounding Python code, creating a governance harness that forces a small, "unruly" model to perform a high-precision task.

---

## 2. The Challenge: Model Drift in Small-Scale LLMs

The primary obstacle in using small models for analytical reports is **model drift**. Based on the enforcement mechanisms in the provided agent, drift can be categorized into three main types:

### 2.1. Affective Drift
This is the tendency of the model to optimize for "user comfort" or "helpfulness" rather than analytical rigor. It involves:
- Injecting emotional cushioning
- Avoiding harsh conclusions
- "Balancing" criticism with praise

The `AffectiveFirewall` module is designed specifically to combat this by prohibiting "reassuring caveats" and "emotional cushioning".

### 2.2. Cadence Drift
This is the most common failure mode, where the model's output becomes weak and non-committal. It is characterized by the insertion of **hedging language**:
- `"perhaps"`, `"might"`, `"could be"`
- `"it seems"`, `"tends to"`, `"arguably"`

This drift is a direct violation of the agent's constitutional **Principle 2: Precision over Consensus**, which states: *"Avoid hedging language when evidence is clear"*.

### 2.3. Structural Drift
This is the inability of the model to follow complex formatting instructions over a long-form output. It may:
- Forget to include sections
- Mis-label them
- Fail to adhere to the required 7-section template defined in modules like `MODULE_SWEEP_REPORT_TEMPLATE_DIRECTIVE`

---

## 3. The Sequential Dialogue Architecture (SDA)

The SDA solves these problems by **not running a single-pass generation**. Instead, it reframes the task as an 8-step, stateful "dialogue" between the Python orchestrator and the LLM. The `Orchestrator` class in `protocol_ai.py` initiates this process by calling `section_by_section_analysis`.

### 3.1. Architectural Overview

The core of the SDA is an 8-step loop in [`section_by_section_analysis.py`](section_by_section_analysis.py):

| Step | Type | Description |
|------|------|-------------|
| **1-5** | LLM Generation | Orchestrator iterates from `section_num = 1` to `5`. In each iteration, it generates only that single section. |
| **6-7** | Python Generation | Sections 6 and 7 are **not** generated by the LLM. They are deterministically created by Python. |
| **8** | Final Assembly | A formatting tool assembles the final report. |

### 3.2. The Multi-Turn Generation Process

The "dialogue" aspect of the architecture is its most critical component:

**Turn 1 (Section 1):**
The orchestrator calls the LLM, instructing it to generate **only Section 1**.

**Turn 2 (Section 2):**
The orchestrator creates a new prompt. This prompt instructs the LLM to generate **only Section 2**, but it also includes the full text of the generated Section 1 as "previous context".

**Turns 3-5 (Continuation):**
This process repeats. The prompt for Section 5 contains the full, finalized, and audited text of Sections 1, 2, 3, and 4.

> **Key Insight:** This stateful, turn-by-turn process ensures the model only has one simple job at a time (*"Write Section 3"*) while still having the necessary context from all previous steps to inform its analysis.

---

## 4. Deterministic Governance and Enforcement

The true power of the SDA lies in its **multi-layer, deterministic enforcement protocol**. The system is built on a *"distrust and verify"* principle, assuming the LLM will fail and building programmatic guardrails to catch and correct that failure.

### 4.1. Layer 1: Per-Turn Prompt Injection

At the start of every turn, the `create_section_prompt` function dynamically builds the prompt. This prompt is not a simple request; it is a **"governance package"** that includes:

- **Task Instructions:** `"Your task is to generate SECTION {section_num}"`
- **Governance Modules:** It injects the full text of anti-drift modules like `AffectiveFirewall` and `CadenceNeutralization` into the prompt every single time. This "resets" the model's instructions and reminds it of the non-negotiable rules for this specific turn.
- **Aggressive Rules:** The prompt includes `"BANNED PHRASES"`, `"CRITICAL INSTRUCTIONS"`, and a `"TOKEN BUDGET"` specific to that section, explicitly forbidding truncation messages or meta-commentary (e.g., `"DO NOT write '[... additional concepts truncated ...]'"`).

### 4.2. Layer 2: Programmatic Audit and Retry Loop

After the LLM generates the text for a section, the orchestrator **does not trust** that it followed the instructions.

```python
# Audit: Scan for drift patterns
drift_in_section = count_drift_patterns([section_text])
total_drift = sum(drift_in_section.values())

# Verify: Check if drift-free
if total_drift == 0:
    sections.append(section_text)  # Accept
    break
else:
    # Enforce: Regenerate with stronger warning
    print(f"✗ Drift detected. Regenerating (attempt {attempt+2})...")
```

**Process:**
1. **Audit:** The Python code immediately calls `count_drift_patterns`, a deterministic function that scans the generated text for a pre-defined list of hedge words (*"perhaps," "might," "it seems," "tends to,"* etc.).
2. **Verify:** It checks if `total_drift == 0`.
3. **Enforce:** If drift is detected, the system discards the LLM's output. It then regenerates the prompt, this time with a stronger warning: `"ANTI-DRIFT ENFORCEMENT (Attempt 2)... PREVIOUS ATTEMPT FAILED DRIFT CHECK."` This retry loop continues for a set number of `max_retries`.

### 4.3. Layer 3: Deterministic Fallback and Bypassing

The system's final layer of enforcement is to **remove the LLM from the loop entirely**.

#### Deterministic Fallback
If the LLM still produces drifted output after 3 retries, the orchestrator gives up. It accepts the final "drifted" output and runs `remove_drift_words`, a Python function that uses RegEx to deterministically strip the banned words from the text.

```python
# Python removes drift words deterministically
cleaned_text, removed_count = remove_drift_words(section_text)
print(f"✓ Python successfully removed {removed_count} drift words")
```

#### LLM Bypassing
The architecture recognizes that some tasks are too critical to entrust to an LLM, no matter how constrained:

- **Section 6 (System Performance Audit):** This section is **100% Python-generated**. The orchestrator calls `count_drift_patterns` on the final versions of Sections 1-5 and then calls `generate_drift_report` to create the audit. The LLM is never involved.

- **Section 7 (Standardized Epistemic Lens):** This is a hard-coded string injected directly by the Python script at the end of the report:
  ```python
  section_7_text = "This analysis prioritizes observable systemic dynamics and structural logic..."
  ```

---

## 5. Conclusion: Forcing Sanity on Small Models

The **Sequential Dialogue Architecture (SDA)** is a highly effective governance harness that demonstrates a new path for building reliable agents from small, efficient LLMs. It successfully mitigates model drift by **externalizing the "discipline" and "sanity"** from the model's weights into a deterministic, verifiable, and enforceable Python-based orchestration script.

### Key Achievements

By breaking a complex, high-failure-rate task into a series of simple, low-failure-rate "dialogue turns," the SDA achieves its goal. Each turn is individually governed, audited, and enforced before it is committed to the final report's state.

This hybrid, **"distrust and verify"** approach allows a 7B model to produce:
- ✅ Structurally-sound reports
- ✅ Precise, analytically-dense content
- ✅ Freedom from affective drift and hedging language

This proves that with a sufficiently rigorous external harness, **smaller models can be forced to perform tasks with the precision and reliability of their much larger counterparts**.

---

## Implementation

See [`section_by_section_analysis.py`](section_by_section_analysis.py) for the full implementation of the 8-step dialogue loop and enforcement mechanisms.
